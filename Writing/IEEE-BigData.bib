
@article{rosenzweig_scarcity_2003,
	title = {Scarcity or {Abundance}? {Preserving} the {Past} in a {Digital} {Era}},
	volume = {108},
	copyright = {Copyright © 2003 American Historical Association},
	issn = {0002-8762},
	shorttitle = {Scarcity or {Abundance}?},
	url = {http://www.jstor.org/stable/10.1086/529596},
	doi = {10.1086/529596},
	number = {3},
	urldate = {2013-05-29},
	journal = {The American Historical Review},
	author = {Rosenzweig, Roy},
	month = jun,
	year = {2003},
	note = {ArticleType: research-article / Full publication date: June 2003 / Copyright © 2003 American Historical Association},
	pages = {735--762},
	file = {JSTOR Full Text PDF:/Users/ianmilligan1/Library/Application Support/Firefox/Profiles/k06azhve.default/zotero/storage/DDC42B9A/Rosenzweig - 2003 - Scarcity or Abundance Preserving the Past in a Di.pdf:application/pdf}
}

@book{moretti_graphs_2007,
	title = {Graphs, {Maps}, {Trees}: {Abstract} {Models} for {Literary} {History}},
	isbn = {1-84467-185-2},
	shorttitle = {Graphs, {Maps}, {Trees}},
	publisher = {Verso},
	author = {Moretti, Franco},
	month = sep,
	year = {2007}
}

@article{schneider_web_2004,
	title = {The {Web} as an {Object} of {Study}},
	volume = {6},
	number = {1},
	journal = {New Media \& Society},
	author = {Schneider, Steven M. and Foot, Kirsten A.},
	year = {2004},
	pages = {114--122}
}

@book{rogers_digital_2013,
	address = {Cambridge, Mass},
	title = {Digital {Methods}},
	abstract = {A proposal to repurpose Web-native techniques for use in social and cultural scholarly research.},
	urldate = {2015-10-27},
	publisher = {MIT Press},
	author = {Rogers, Richard},
	year = {2013},
	file = {Snapshot:/Users/ianmilligan1/Library/Application Support/Firefox/Profiles/k06azhve.default/zotero/storage/REA5HCXQ/digital-methods.html:text/html}
}

@article{dougherty_community_2014,
	title = {Community, tools, and practices in web archiving: {The} state-of-the-art in relation to social science and humanities research needs},
	volume = {65},
	copyright = {© 2014 ASIS\&T},
	issn = {2330-1643},
	shorttitle = {Community, tools, and practices in web archiving},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/asi.23099/abstract},
	doi = {10.1002/asi.23099},
	abstract = {The web encourages the constant creation and distribution of large amounts of information; it is also a valuable resource for understanding human behavior and communication. To take full advantage of the web as a research resource that extends beyond the consideration of snapshots of the present, however, it is necessary to begin to take web archiving much more seriously as an important element of any research program involving web resources. The ephemeral character of the web requires that researchers take proactive steps in the present to enable future analysis. Efforts to archive the web or portions thereof have been developed around the world, but these efforts have not yet provided reliable and scalable solutions. This article summarizes the current state of web archiving in relation to researchers and research needs. Interviews with researchers, archivists, and technologists identify the differences in purpose, scope, and scale of current web archiving practice, and the professional tensions that arise given these differences. Findings outline the challenges that still face researchers who wish to engage seriously with web content as an object of research, and archivists who must strike a balance reflecting a range of user needs.},
	language = {en},
	number = {11},
	urldate = {2015-05-04},
	journal = {J Assn Inf Sci Tec},
	author = {Dougherty, Meghan and Meyer, Eric T.},
	month = nov,
	year = {2014},
	keywords = {Archives, digital object preservation, World Wide Web},
	pages = {2195--2209},
	file = {Full Text PDF:/Users/ianmilligan1/Library/Application Support/Firefox/Profiles/k06azhve.default/zotero/storage/HPP3AF5A/Dougherty and Meyer - 2014 - Community, tools, and practices in web archiving .pdf:application/pdf;Snapshot:/Users/ianmilligan1/Library/Application Support/Firefox/Profiles/k06azhve.default/zotero/storage/U4688DCM/abstract.html:text/html}
}

@misc{brugger_studying_2015,
	address = {Palo Alto, California},
	title = {Studying a nation's web domain over time: analytical and methodological considerations},
	url = {http://netpreserve.org/sites/default/.../2015_IIPC-GA_Slides_02_Brugger.pptx},
	urldate = {2015-07-27},
	author = {Br\"ugger, Niels and Laursen, Ditte and Nielsen, Janne},
	month = apr,
	year = {2015}
}

@book{brugger_archiving_2005,
	address = {Aarhus},
	title = {Archiving {Websites}: {General} {Considerations} and {Strategies}},
	publisher = {Center for Internetforskning},
	author = {Br\"ugger, Niels},
	year = {2005}
}

@book{graham_exploring_2015,
	address = {London},
	title = {Exploring {Big} {Historical} {Data}: {The} {Historian}'s {Macroscope}},
	isbn = {978-1-78326-608-1 978-1-78326-610-4},
	shorttitle = {Exploring {Big} {Historical} {Data}},
	url = {http://www.worldscientific.com/worldscibooks/10.1142/p981},
	language = {en},
	urldate = {2015-09-18},
	publisher = {Imperial College Press},
	author = {Graham, Shawn and Milligan, Ian and Weingart, Scott},
	month = nov,
	year = {2015}
}

@article{milligan_lost_2016,
	title = {Lost in the {Infinite} {Archive}: {The} {Promise} and {Pitfalls} of {Web} {Archives}},
	volume = {10},
	issn = {1753-8548},
	shorttitle = {Lost in the {Infinite} {Archive}},
	url = {http://www.euppublishing.com/doi/abs/10.3366/ijhac.2016.0161},
	doi = {10.3366/ijhac.2016.0161},
	abstract = {Contemporary and future historians need to grapple with and confront the challenges posed by web archives. These large collections of material, accessed either through the Internet Archive's Wayback Machine or through other computational methods, represent both a challenge and an opportunity to historians. Through these collections, we have the potential to access the voices of millions of non-elite individuals (recognizing of course the cleavages in both Web access as well as method of access). To put this in perspective, the Old Bailey Online currently describes its monumental holdings of 197,745 trials between 1674 and 1913 as the “largest body of texts detailing the lives of non-elite people ever published.” GeoCities.com, a platform for everyday web publishing in the mid-to-late 1990s and early 2000s, amounted to over thirty-eight million individual webpages. Historians will have access, in some form, to millions of pages: written by everyday people of various classes, genders, ethnicities, and ages....},
	number = {1},
	urldate = {2016-04-08},
	journal = {Intl J Humanities \& Arts Computing},
	author = {Milligan, Ian},
	month = mar,
	year = {2016},
	keywords = {archive, Digital History, historical studies, webscraping, World Wide Web},
	pages = {78--94},
	file = {EUP Snapshot:/Users/ianmilligan1/Library/Application Support/Firefox/Profiles/k06azhve.default/zotero/storage/UE337JEZ/ijhac.2016.html:text/html}
}

@inproceedings{milligan_content_2016,
	address = {Newark, New Jersey},
	title = {Content {Selection} and {Curation} for {Web} {Archiving}: {The} {Gatekeepers} vs. the {Masses}},
	booktitle = {Processings of the {Joint} {Conference} on {Digital} {Libraries}},
	publisher = {ACM},
	author = {Milligan, Ian and Ruest, Nick and Lin, Jimmy},
	year = {2016}
}

@article{borgman_digital_2009,
	title = {The {Digital} {Future} is {Now}: {A} {Call} to {Action} for the {Humanities}},
	volume = {3},
	shorttitle = {The {Digital} {Future} is {Now}},
	url = {http://www.digitalhumanities.org/dhq/vol/3/4/000077/000077.html},
	number = {4},
	urldate = {2016-10-04},
	author = {Borgman, Christine L.},
	year = {2009},
	file = {DHQ Snapshot:/Users/ianmilligan1/Library/Application Support/Firefox/Profiles/k06azhve.default/zotero/storage/ZREC4KJK/000077.html:text/html}
}

@article{bechhofer_why_2013,
	series = {Special section: {Recent} advances in e-{Science}},
	title = {Why linked data is not enough for scientists},
	volume = {29},
	issn = {0167-739X},
	url = {http://www.sciencedirect.com/science/article/pii/S0167739X11001439},
	doi = {10.1016/j.future.2011.08.004},
	abstract = {Scientific data represents a significant portion of the linked open data cloud and scientists stand to benefit from the data fusion capability this will afford. Publishing linked data into the cloud, however, does not ensure the required reusability. Publishing has requirements of provenance, quality, credit, attribution and methods to provide the reproducibility that enables validation of results. In this paper we make the case for a scientific data publication model on top of linked data and introduce the notion of Research Objects as first class citizens for sharing and publishing.},
	number = {2},
	urldate = {2016-10-04},
	journal = {Future Generation Computer Systems},
	author = {Bechhofer, Sean and Buchan, Iain and De Roure, David and Missier, Paolo and Ainsworth, John and Bhagat, Jiten and Couch, Philip and Cruickshank, Don and Delderfield, Mark and Dunlop, Ian and Gamble, Matthew and Michaelides, Danius and Owen, Stuart and Newman, David and Sufi, Shoaib and Goble, Carole},
	month = feb,
	year = {2013},
	keywords = {Linked data, Publishing, Reproducibility, Research object, Reuse, sharing},
	pages = {599--611},
	file = {ScienceDirect Full Text PDF:/Users/ianmilligan1/Library/Application Support/Firefox/Profiles/k06azhve.default/zotero/storage/G4UWVZHU/Bechhofer et al. - 2013 - Why linked data is not enough for scientists.pdf:application/pdf;ScienceDirect Snapshot:/Users/ianmilligan1/Library/Application Support/Firefox/Profiles/k06azhve.default/zotero/storage/EUM45KT7/S0167739X11001439.html:text/html}
}

@article{ben-david_web_2014,
	title = {Web {Archive} {Search} as {Research}: {Methodological} and {Theoretical} {Implications}},
	volume = {25},
	issn = {0955-7490, 2050-4551},
	shorttitle = {Web {Archive} {Search} as {Research}},
	url = {http://ala.sagepub.com/content/25/1-2/93},
	doi = {10.7227/ALX.0022},
	abstract = {The field of web archiving is at a turning point. In the early years of web archiving, the single URL has been the dominant unit for preservation and access. Access tools such as the Internet Archive's Wayback Machine reflect this notion as they allowed consultation, or browsing, of one URL at a time. In recent years, however, the single URL approach to accessing web archives is being gradually replaced by search interfaces. This paper addresses the theoretical and methodological implications of the transition to search on web archive research. It introduces ‘search as research’ methods, practices already applied in studies of the live web, which can be repurposed and implemented for critically studying archived web data. Such methods open up a variety of analytical practices that were so far precluded by the single URL entry point to the web archive, such as the re-assemblage of existing collections around a theme or an event, the study of archival artefacts and scaling the unit of analysis from the single URL to the full archive, by generating aggregate views and summaries. The paper introduces examples to ‘search as research’ scenarios, which have been developed by the WebART project at the University of Amsterdam and the Centrum Wiskunde \& Informatica, in collaboration with the National Library of the Netherlands. The paper concludes with a discussion of current and potential limitations of ‘search as research’ methods for studying web archives, and the ways with which they can be overcome in the near future.},
	language = {en},
	number = {1-2},
	urldate = {2016-10-04},
	journal = {Alexandria},
	author = {Ben-David, Anat and Huurdeman, Hugo},
	month = aug,
	year = {2014},
	keywords = {Internet Archive, national libraries, search, Wayback Machine, Web Archives},
	pages = {93--111},
	file = {Full Text PDF:/Users/ianmilligan1/Library/Application Support/Firefox/Profiles/k06azhve.default/zotero/storage/6H2BXDBG/Ben-David and Huurdeman - 2014 - Web Archive Search as Research Methodological and.pdf:application/pdf;Snapshot:/Users/ianmilligan1/Library/Application Support/Firefox/Profiles/k06azhve.default/zotero/storage/PG5I62ZN/93.html:text/html}
}

@misc{deswarte_revealing_2015,
	type = {conference},
	title = {Revealing {British} {Euroscepticism} in the {UK} {Web} {Domain} and {Archive} {Case} {Study}},
	copyright = {cc\_by\_nd},
	url = {http://sas-space.sas.ac.uk/6103/#undefined},
	abstract = {A case study of the use of web archives for historical research, focusing on British Euroscepticism.},
	language = {en},
	urldate = {2016-10-04},
	author = {Deswarte, Richard},
	month = jul,
	year = {2015},
	file = {Full Text PDF:/Users/ianmilligan1/Library/Application Support/Firefox/Profiles/k06azhve.default/zotero/storage/CV73VIR8/Deswarte - 2015 - Revealing British Euroscepticism in the UK Web Dom.pdf:application/pdf;Snapshot:/Users/ianmilligan1/Library/Application Support/Firefox/Profiles/k06azhve.default/zotero/storage/QX82AB4T/6103.html:text/html}
}

@book{masanes_web_2006,
	address = {Berlin, Heidelberg},
	title = {Web {Archiving}},
	isbn = {978-3-540-23338-1 978-3-540-46332-0},
	url = {http://link.springer.com/10.1007/978-3-540-46332-0},
	language = {en},
	urldate = {2016-10-04},
	publisher = {Springer Berlin Heidelberg},
	author = {Masanés, Julien},
	year = {2006}
}

@article{ben-david_what_2016,
	title = {What does the {Web} remember of its deleted past? {An} archival reconstruction of the former {Yugoslav} top-level domain},
	issn = {1461-4448, 1461-7315},
	shorttitle = {What does the {Web} remember of its deleted past?},
	url = {http://nms.sagepub.com/content/early/2016/04/27/1461444816643790},
	doi = {10.1177/1461444816643790},
	abstract = {This article argues that the use of the Web as a primary source for studying the history of nations is conditioned by the structural ties between sovereignty and the Internet protocol, and by a temporal proximity between live and archived websites. The argument is illustrated by an empirical reconstruction of the history of the top-level domain of Yugoslavia (.yu), which was deleted from the Internet in 2010. The archival discovery method used four lists of historical .yu Uniform Resource Locators (URLs) that were captured from the live Web before the domain was deleted, and an automated hyperlink discovery script that retrieved their snapshots from the Internet Archive and reconstructed their immediate hyperlinked environment in a network. Although a considerable portion of the historical .yu domain was found on the Internet Archive, the reconstructed space was predominantly Serbian.},
	language = {en},
	urldate = {2016-10-04},
	journal = {New Media Society},
	author = {Ben-David, Anat},
	month = apr,
	year = {2016},
	keywords = {Country code top-level domain, digital heritage, Internet Archive, Internet Corporation for Assigned Names and Numbers, national Webs, Serbia, Wayback Machine, Web Archives, web history, Yugoslavia},
	pages = {1461444816643790},
	file = {Full Text PDF:/Users/ianmilligan1/Library/Application Support/Firefox/Profiles/k06azhve.default/zotero/storage/3FM9TM57/Ben-David - 2016 - What does the Web remember of its deleted past An.pdf:application/pdf;Snapshot:/Users/ianmilligan1/Library/Application Support/Firefox/Profiles/k06azhve.default/zotero/storage/NS2G2UAD/1461444816643790.html:text/html}
}

@book{brugger_web_2017,
	address = {London},
	title = {The {Web} as {History}},
	url = {https://www.ucl.ac.uk/ucl-press/browse-books/the-web-as-history},
	urldate = {2016-10-04},
	publisher = {UCL Press},
	editor = {Br\"ugger, Niels and Schroeder, Ralph},
	year = {2017},
	file = {Snapshot:/Users/ianmilligan1/Library/Application Support/Firefox/Profiles/k06azhve.default/zotero/storage/WZQME353/the-web-as-history.html:text/html}
}

@article{weltevrede_where_2012,
	title = {Where do bloggers blog? {Platform} transitions within the historical {Dutch} blogosphere},
	volume = {17},
	copyright = {Authors submitting a paper to First Monday automatically agree to confer a limited license to First Monday if and when the manuscript is accepted for publication. This license allows First Monday to publish a manuscript in a given issue. Authors have a choice of: 1. Dedicating the article to the public domain. This allows anyone to make any use of the article at any time, including commercial use. A good way to do this is to use the Creative Commons Public Domain Dedication Web form; see  http://creativecommons.org/license/publicdomain-2?lang=en . 2. Retaining some rights while allowing some use. For example, authors may decide to disallow commercial use without permission. Authors may also decide whether to allow users to make modifications (e.g. translations, adaptations) without permission. A good way to make these choices is to use a Creative Commons license. * Go to  http://creativecommons.org/license/ . * Choose and select a license. * What to do next — you can then e–mail the license html code to yourself. Do this, and then forward that e–mail to First Monday’s editors. Put your name in the subject line of the e–mail with your name and article title in the e–mail. Background information about Creative Commons licenses can be found at  http://creativecommons.org/about/licenses/ . 3. Retaining full rights, including translation and reproduction rights. Authors may use the statement: © Author 2016 All Rights Reserved. Authors may choose to use their own wording to reserve copyright. If you choose to retain full copyright, please add your copyright statement to the end of the article. Authors submitting a paper to First Monday do so in the understanding that Internet publishing is both an opportunity and challenge. In this environment, authors and publishers do not always have the means to protect against unauthorized copying or editing of copyright–protected works.},
	issn = {13960466},
	shorttitle = {Where do bloggers blog?},
	url = {http://firstmonday.org/ojs/index.php/fm/article/view/3775},
	language = {en},
	number = {2},
	urldate = {2016-10-04},
	journal = {First Monday},
	author = {Weltevrede, Esther and Helmond, Anne},
	month = feb,
	year = {2012},
	keywords = {Blogosphere, blog software, digital methods, hyperlink networks, social media},
	file = {Snapshot:/Users/ianmilligan1/Library/Application Support/Firefox/Profiles/k06azhve.default/zotero/storage/Q7RVWFUD/3142.html:text/html}
}

@misc{weber_big_2016,
	address = {Atlanta, Georgia},
	title = {From {Big} {Data} to {Big} {Theory}: {Lessons} {Learned} from {Archival} {Internet} {R}…},
	shorttitle = {From {Big} {Data} to {Big} {Theory}},
	url = {http://www.slideshare.net/mwe400/from-big-data-to-big-theory-lessons-learned-from-archival-internet-research},
	urldate = {2016-10-04},
	year = {2016},
	author = {Weber, Matthew S.}
}

@article{bailey_disrespect_2013,
	title = {Disrespect des {Fonds}: {Rethinking} {Arrangement} and {Description} in {Born}-{Digital} {Archives} - {Archive} {Journal} {Issue} 3},
	shorttitle = {Disrespect des {Fonds}},
	url = {http://www.archivejournal.net/issue/3/archives-remixed/disrespect-des-fonds-rethinking-arrangement-and-description-in-born-digital-archives/},
	number = {3},
	urldate = {2016-10-04},
	journal = {Archive Journal},
	author = {Bailey, Jefferson},
	year = {2013},
	file = {Snapshot:/Users/ianmilligan1/Library/Application Support/Firefox/Profiles/k06azhve.default/zotero/storage/9QIQKVCW/disrespect-des-fonds-rethinking-arrangement-and-description-in-born-digital-archives.html:text/html}
}

@inproceedings{paz_curate_2016,
	title = {Curate my web crawl: {Building} a multiprocessing web crawler for ethnographic research},
	url = {http://2016.code4lib.org/Curate-my-web-crawl-Building-a-multiprocessing-web-crawler-for-ethnographic-research},
	urldate = {2016-10-04},
	author = {Paz, Alejandro and Pham, Kim and Stapelfeldt, Kirsta},
	year = {2016},
	file = {Curate my web crawl\: Building a multiprocessing web crawler for ethnographic research:/Users/ianmilligan1/Library/Application Support/Firefox/Profiles/k06azhve.default/zotero/storage/WWKRKI4G/Curate-my-web-crawl-Building-a-multiprocessing-web-crawler-for-ethnographic-research.html:text/html}
}

@article{dallas_digital_2015,
	title = {Digital curation beyond the “wild frontier”: a pragmatic approach},
	issn = {1389-0166, 1573-7519},
	shorttitle = {Digital curation beyond the “wild frontier”},
	url = {http://link.springer.com/article/10.1007/s10502-015-9252-6},
	doi = {10.1007/s10502-015-9252-6},
	abstract = {This paper advocates the necessity of developing a pragmatic alternative to the dominant custodial theorization of digital curation as an “umbrella concept for digital preservation, data curation, electronic records, and digital asset management”. Starting from a historical account and an examination of prevalent definitions, it points to the current dependence of digital curation on a prescriptive approach rooted in its cognate field of digital preservation, aiming to serve the needs of professional stewardship. It demonstrates the disconnect of this theorization with the rich historical traditions of museum curatorship where the notion of curation originated, its inability to act as a framework for understanding the diversity and pervasiveness of contemporary digital curation practices “in the wild” (such as content curation, personal archiving, and pro-am digitization), and its dependence on a “wild frontier” ideology dissonant with contemporary critical cultural heritage scholarship. The alternative, pragmatic approach views digital curation as a “contact zone” practice, routinely performed by a broad range of actors including researchers, artists, users, and communities, on dynamically evolving objects, domain knowledge representations, and interactions, beyond the curation life cycle prescribed for custodial environments. On this basis, this study calls for a formal reconceptualization of digital curation, adequate knowledge representation of its objects, evidence-based research on curation practices, and establishment of curation-enabled digital infrastructures suitable for curation in the continuum. Reaching beyond a custodial view, this approach aims to establish digital curation as a field of intellectual inquiry relevant to emerging pervasive curation practices in the digital environment.},
	language = {en},
	urldate = {2016-10-04},
	journal = {Arch Sci},
	author = {Dallas, Costis},
	month = sep,
	year = {2015},
	pages = {1--37},
	file = {Full Text PDF:/Users/ianmilligan1/Library/Application Support/Firefox/Profiles/k06azhve.default/zotero/storage/IP2PADH5/Dallas - 2015 - Digital curation beyond the “wild frontier” a pra.pdf:application/pdf;Snapshot:/Users/ianmilligan1/Library/Application Support/Firefox/Profiles/k06azhve.default/zotero/storage/SCSH3R5G/s10502-015-9252-6.html:text/html}
}

@article{belhajjame_using_2015,
	title = {Using a suite of ontologies for preserving workflow-centric research objects},
	volume = {32},
	issn = {1570-8268},
	url = {http://www.sciencedirect.com/science/article/pii/S1570826815000049},
	doi = {10.1016/j.websem.2015.01.003},
	abstract = {Scientific workflows are a popular mechanism for specifying and automating data-driven in silico experiments. A significant aspect of their value lies in their potential to be reused. Once shared, workflows become useful building blocks that can be combined or modified for developing new experiments. However, previous studies have shown that storing workflow specifications alone is not sufficient to ensure that they can be successfully reused, without being able to understand what the workflows aim to achieve or to re-enact them. To gain an understanding of the workflow, and how it may be used and repurposed for their needs, scientists require access to additional resources such as annotations describing the workflow, datasets used and produced by the workflow, and provenance traces recording workflow executions.

In this article, we present a novel approach to the preservation of scientific workflows through the application of research objects—aggregations of data and metadata that enrich the workflow specifications. Our approach is realised as a suite of ontologies that support the creation of workflow-centric research objects. Their design was guided by requirements elicited from previous empirical analyses of workflow decay and repair. The ontologies developed make use of and extend existing well known ontologies, namely the Object Reuse and Exchange (ORE) vocabulary, the Annotation Ontology (AO) and the W3C PROV ontology (PROVO). We illustrate the application of the ontologies for building Workflow Research Objects with a case-study that investigates Huntington’s disease, performed in collaboration with a team from the Leiden University Medial Centre (HG-LUMC). Finally we present a number of tools developed for creating and managing workflow-centric research objects.},
	urldate = {2016-10-04},
	journal = {Web Semantics: Science, Services and Agents on the World Wide Web},
	author = {Belhajjame, Khalid and Zhao, Jun and Garijo, Daniel and Gamble, Matthew and Hettne, Kristina and Palma, Raul and Mina, Eleni and Corcho, Oscar and Gómez-Pérez, José Manuel and Bechhofer, Sean and Klyne, Graham and Goble, Carole},
	month = may,
	year = {2015},
	keywords = {Annotation, Ontologies, preservation, Provenance, Research object, Scientific workflow},
	pages = {16--42},
	file = {ScienceDirect Full Text PDF:/Users/ianmilligan1/Library/Application Support/Firefox/Profiles/k06azhve.default/zotero/storage/FKWKMEN2/Belhajjame et al. - 2015 - Using a suite of ontologies for preserving workflo.pdf:application/pdf;ScienceDirect Snapshot:/Users/ianmilligan1/Library/Application Support/Firefox/Profiles/k06azhve.default/zotero/storage/B8VUX685/S1570826815000049.html:text/html}
}

@article{goodman_ten_2014,
	title = {Ten {Simple} {Rules} for the {Care} and {Feeding} of {Scientific} {Data}},
	volume = {10},
	issn = {1553-7358},
	url = {http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003542},
	doi = {10.1371/journal.pcbi.1003542},
	number = {4},
	urldate = {2016-10-04},
	journal = {PLOS Comput Biol},
	author = {Goodman, Alyssa and Pepe, Alberto and Blocker, Alexander W. and Borgman, Christine L. and Cranmer, Kyle and Crosas, Merce and Stefano, Rosanne Di and Gil, Yolanda and Groth, Paul and Hedstrom, Margaret and Hogg, David W. and Kashyap, Vinay and Mahabal, Ashish and Siemiginowska, Aneta and Slavkovic, Aleksandra},
	month = apr,
	year = {2014},
	keywords = {Archives, Computer software, Data management, Data visualization, Open source software, Scientists, Software tools, Telescopes},
	pages = {e1003542},
	file = {Full Text PDF:/Users/ianmilligan1/Library/Application Support/Firefox/Profiles/k06azhve.default/zotero/storage/MPAP6BZE/Goodman et al. - 2014 - Ten Simple Rules for the Care and Feeding of Scien.pdf:application/pdf;Snapshot:/Users/ianmilligan1/Library/Application Support/Firefox/Profiles/k06azhve.default/zotero/storage/5ZPQIEXH/article.html:text/html}
}

@article{sandve_ten_2013,
	title = {Ten {Simple} {Rules} for {Reproducible} {Computational} {Research}},
	volume = {9},
	issn = {1553-7358},
	url = {http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003285},
	doi = {10.1371/journal.pcbi.1003285},
	number = {10},
	urldate = {2016-10-04},
	journal = {PLOS Comput Biol},
	author = {Sandve, Geir Kjetil and Nekrutenko, Anton and Taylor, James and Hovig, Eivind},
	month = oct,
	year = {2013},
	keywords = {Archives, Computer and information sciences, Computer applications, Habits, Replication studies, Reproducibility, Sequence analysis, Source code},
	pages = {e1003285},
	file = {Full Text PDF:/Users/ianmilligan1/Library/Application Support/Firefox/Profiles/k06azhve.default/zotero/storage/ZCPAFIP7/Sandve et al. - 2013 - Ten Simple Rules for Reproducible Computational Re.pdf:application/pdf;Snapshot:/Users/ianmilligan1/Library/Application Support/Firefox/Profiles/k06azhve.default/zotero/storage/PCZD94I3/article.html:text/html}
}

@article{king_ensuring_2011,
	title = {Ensuring the {Data}-{Rich} {Future} of the {Social} {Sciences}},
	volume = {331},
	copyright = {Copyright © 2011, American Association for the Advancement of Science},
	issn = {0036-8075, 1095-9203},
	url = {http://science.sciencemag.org/content/331/6018/719},
	doi = {10.1126/science.1197872},
	abstract = {Massive increases in the availability of informative social science data are making dramatic progress possible in analyzing, understanding, and addressing many major societal problems. Yet the same forces pose severe challenges to the scientific infrastructure supporting data sharing, data management, informatics, statistical methodology, and research ethics and policy, and these are collectively holding back progress. I address these changes and challenges and suggest what can be done.},
	language = {en},
	number = {6018},
	urldate = {2016-10-04},
	journal = {Science},
	author = {King, Gary},
	month = feb,
	year = {2011},
	pmid = {21311013},
	pages = {719--721},
	file = {Full Text PDF:/Users/ianmilligan1/Library/Application Support/Firefox/Profiles/k06azhve.default/zotero/storage/RIWW58N9/King - 2011 - Ensuring the Data-Rich Future of the Social Scienc.pdf:application/pdf;Snapshot:/Users/ianmilligan1/Library/Application Support/Firefox/Profiles/k06azhve.default/zotero/storage/ZGHRPQ62/719.html:text/html}
}

@book{borgman_big_2015,
	address = {Cambridge, Massachusetts},
	title = {Big {Data}, {Little} {Data}, {No} {Data}: {Scholarship} in the {Networked} {World}},
	isbn = {978-0-262-02856-1},
	shorttitle = {Big {Data}, {Little} {Data}, {No} {Data}},
	abstract = {"Big Data" is on the covers of  Science, Nature, the  Economist, and  Wired magazines, on the front pages of the  Wall Street Journal and the  New York Times. But despite the media hyperbole, as Christine Borgman points out in this examination of data and scholarly research, having the right data is usually better than having more data; little data can be just as valuable as big data. In many cases, there are no data -- because relevant data don't exist, cannot be found, or are not available. Moreover, data sharing is difficult, incentives to do so are minimal, and data practices vary widely across disciplines.Borgman, an often-cited authority on scholarly communication, argues that data have no value or meaning in isolation; they exist within a knowledge infrastructure -- an ecology of people, practices, technologies, institutions, material objects, and relationships. After laying out the premises of her investigation -- six "provocations" meant to inspire discussion about the uses of data in scholarship -- Borgman offers case studies of data practices in the sciences, the social sciences, and the humanities, and then considers the implications of her findings for scholarly practice and research policy. To manage and exploit data over the long term, Borgman argues, requires massive investment in knowledge infrastructures; at stake is the future of scholarship.},
	language = {English},
	publisher = {The MIT Press},
	author = {Borgman, Christine L.},
	month = jan,
	year = {2015}
}

@article{ruest_open-source_2016,
	title = {An {Open}-{Source} {Strategy} for {Documenting} {Events}: {The} {Case} {Study} of the 42nd {Canadian} {Federal} {Election} on {Twitter}},
	issn = {1940-5758},
	shorttitle = {An {Open}-{Source} {Strategy} for {Documenting} {Events}},
	url = {http://journal.code4lib.org/articles/11358},
	abstract = {This article examines the tools, approaches, collaboration, and findings of the Web Archives for Historical Research Group around the capture and analysis of about 4 million tweets during the 2015 Canadian Federal Election. We hope that national libraries and other heritage institutions will find our model useful as they consider how to capture, preserve, and analyze ongoing events using Twitter., While Twitter is not a representative sample of broader society – Pew research shows in their study of US users that it skews young, college-educated, and affluent (above \$50,000 household income) – Twitter still represents an exponential increase in the amount of information generated, retained, and preserved from 'everyday' people. Therefore, when historians study the 2015 federal election, Twitter will be a prime source., On August 3, 2015, the team initiated both a Search API and Stream API collection with twarc, a tool developed by Ed Summers, using the hashtag \#elxn42. The hashtag referred to the election being Canada's 42nd general federal election (hence 'election 42' or elxn42). Data collection ceased on November 5, 2015, the day after Justin Trudeau was sworn in as the 42nd Prime Minister of Canada. We collected for a total of 102 days, 13 hours and 50 minutes., To analyze the data set, we took advantage of a number of command line tools, utilities that are available within twarc, twarc-report, and jq. In accordance with the Twitter Developer Agreement \& Policy, and after ethical deliberations discussed below, we made the tweet IDs and other derivative data available in a data repository. This allows other people to use our dataset, cite our dataset, and enhance their own research projects by drawing on \#elxn42 tweets., Our analytics included:, Our article introduces our collecting work, ethical considerations, the analysis we have done, and provides a framework for other collecting institutions to do similar work with our off-the-shelf open-source tools. We conclude by ruminating about connecting Twitter archiving with a broader web archiving strategy.},
	number = {32},
	urldate = {2016-10-04},
	journal = {The Code4Lib Journal},
	author = {Ruest, Nick and Milligan, Ian},
	month = apr,
	year = {2016},
	file = {Code4Lib Journal Snapshot:/Users/ianmilligan1/Library/Application Support/Firefox/Profiles/k06azhve.default/zotero/storage/H43GIQ7C/11358.html:text/html}
}

@misc{summers_edsu/twarc_2016,
	title = {edsu/twarc},
	url = {https://github.com/edsu/twarc},
	abstract = {twarc - A command line tool (and Python library) for archiving Twitter JSON},
	urldate = {2016-10-04},
	journal = {GitHub},
	author = {Summers, Ed},
	year = {2016},
	file = {Snapshot:/Users/ianmilligan1/Library/Application Support/Firefox/Profiles/k06azhve.default/zotero/storage/PRSUARG2/twarc.html:text/html}
}

@incollection{milligan_welcome_2017,
	address = {London},
	title = {Welcome to the {Web}: {The} {Online} {Community} of {GeoCities} and the {Early} {Years} of the {World} {Wide} {Web}},
	booktitle = {The {Web} as {History}},
	publisher = {UCL Press},
	author = {Milligan, Ian},
	editor = {Brügger, Niels and Schroeder, Ralph},
	year = {2017}
}

@misc{milligan_institutional_2015,
	title = {Institutional vs. {Twitter} {Seed} {Lists} for {Web} {Archives}},
	url = {https://ianmilligan.ca/2015/11/26/institutional-vs-twitter-seed-lists-for-web-archives/},
	abstract = {With Nick Ruest and William Turkel, I’ve been exploring the tweets of the 42nd Canadian federal election that used the \#elxn42 hashtag. Having also been part of the team that launched WebArch…},
	urldate = {2016-10-04},
	journal = {Ian Milligan},
	author = {Milligan, Ian},
	month = nov,
	year = {2015},
	file = {Snapshot:/Users/ianmilligan1/Library/Application Support/Firefox/Profiles/k06azhve.default/zotero/storage/XAKDZGH8/institutional-vs-twitter-seed-lists-for-web-archives.html:text/html}
}